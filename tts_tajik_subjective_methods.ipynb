{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " **ğŸ”ŠVoice Cloning Similarity (VCS)**\n",
        "\n",
        " This code compares how similar a generated voice is to a reference voice. It does this by converting both audio files into embeddings (numerical voice representations) using the **Resemblyzer** model, then calculating the cosine similarity between them. The result is shown as a percentage, where higher values mean the generated speech is closer to the original speakerâ€™s voice.\n"
      ],
      "metadata": {
        "id": "D3v4Ov7rOUbM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVz6PPaqOKsS"
      },
      "outputs": [],
      "source": [
        "# Install required packages:\n",
        "pip install resemblyzer numpy soundfile\n",
        "from resemblyzer import VoiceEncoder, preprocess_wav\n",
        "import numpy as np\n",
        "\n",
        "encoder = VoiceEncoder()\n",
        "# Load reference and generated audio\n",
        "ref_wav = preprocess_wav(\"reference_vcs.wav\")\n",
        "gen_wav = preprocess_wav(\"gpt_generated_vcs.wav\")\n",
        "\n",
        "# Compute embeddings\n",
        "ref_embed = encoder.embed_utterance(ref_wav)\n",
        "gen_embed = encoder.embed_utterance(gen_wav)\n",
        "\n",
        "# Cosine similarity\n",
        "similarity = np.dot(ref_embed, gen_embed) / (np.linalg.norm(ref_embed) * np.linalg.norm(gen_embed))\n",
        "\n",
        "# Convert to percentage and round to 1 decimal place\n",
        "similarity_percent = round(similarity * 100, 1)\n",
        "print(\"Similarity (%):\", similarity_percent)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ğŸ•’ Real-Time Factor (RTF)**\n",
        "\n",
        "The following code provides a general template for measuring the Real-Time Factor (RTF) of any Text-to-Speech (TTS) system. It takes a sample text, synthesizes speech using the chosen model, records the time taken for synthesis, and compares it with the actual audio duration. From this, the RTF is calculated, showing how fast the model generates speech relative to real time. Additionally, an optional scoring function converts the RTF value into a 0â€“5 scale for easier comparison between models."
      ],
      "metadata": {
        "id": "y2g87QYuPMyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import soundfile as sf\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "text = (\n",
        "    \"Ğ¡ÑƒĞ±Ò³ Ğ±Ğ°Ñ€Ğ²Ğ°Ò›Ñ‚ Ğ±ĞµĞ´Ğ¾Ñ€ ÑˆÑƒĞ´Ğ°Ğ¼. \"\n",
        "    \"Ğ‘Ğ° Ğ¾ÑˆÑ…Ğ¾Ğ½Ğ° Ñ€Ğ°Ñ„Ñ‚Ğ°Ğ¼ Ğ²Ğ° Ñ‡Ğ¾Ğ¹ Ğ½Ó¯ÑˆĞ¸Ğ´ĞµĞ¼. \"\n",
        "    \"Ğ¡ÑƒĞ±Ò³Ğ¾Ğ½Ğ° Ğ¾Ğ¼Ğ¾Ğ´Ğ° ĞºĞ°Ñ€Ğ´Ğ°Ğ¼ Ğ²Ğ° Ğ±Ğ° Ñ…Ğ¾Ğ½Ğ° Ñ…Ó¯Ñ€Ğ¾Ğº Ñ…Ó¯Ñ€Ğ´ĞµĞ¼. \"\n",
        "    \"Ğ‘Ğ°ÑŠĞ´ Ğ±Ğ° Ğ±Ğ¾Ğ·Ğ¾Ñ€ Ñ€Ğ°Ñ„Ñ‚Ğ°Ğ¼.\"\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# âœ… Placeholder TTS function\n",
        "# Replace this with the API call / model inference\n",
        "# -----------------------------\n",
        "def synthesize_text(text, output_file=\"output.wav\"):\n",
        "    \"\"\"\n",
        "    General TTS synthesis function.\n",
        "    Replace this part with:\n",
        "      - OpenAI API call\n",
        "      - Hugging Face pipeline\n",
        "      - Local TTS model inference\n",
        "    \"\"\"\n",
        "    # Example (OpenAI):\n",
        "    # response = openai.audio.speech.create(\n",
        "    #     model=\"gpt-4o-mini-tts\",\n",
        "    #     voice=\"alloy\",\n",
        "    #     input=text\n",
        "    # )\n",
        "    # audio_bytes = response.read()\n",
        "    # with open(output_file, \"wb\") as f:\n",
        "    #     f.write(audio_bytes)\n",
        "\n",
        "    # For now just assume output.wav exists\n",
        "    return output_file\n",
        "\n",
        "def calculate_rtf(text, output_file=\"output.wav\"):\n",
        "    start_time = time.time()\n",
        "    synthesize_text(text, output_file=output_file)  # Run TTS\n",
        "    end_time = time.time()\n",
        "\n",
        "    synthesis_time = end_time - start_time\n",
        "\n",
        "    # Load audio and get duration\n",
        "    audio, sr = sf.read(output_file)\n",
        "    audio_duration = len(audio) / sr\n",
        "\n",
        "    # Real-Time Factor\n",
        "    rtf = synthesis_time / audio_duration\n",
        "    return synthesis_time, audio_duration, rtf\n",
        "\n",
        "def rtf_to_score(rtf):\n",
        "    if rtf >= 2.0:\n",
        "        return 0.0\n",
        "    score = 5.0 * (1.5 - rtf) / 1.5\n",
        "    return round(max(0.0, min(score, 5.0)), 2)\n",
        "\n",
        "synthesis_time, audio_duration, rtf = calculate_rtf(text)\n",
        "rtf_score = rtf_to_score(rtf)\n",
        "\n",
        "print(f\"ğŸ•’ Synthesis Time: {round(synthesis_time, 3)} sec\")\n",
        "print(f\"ğŸ§ Audio Duration: {round(audio_duration, 3)} sec\")\n",
        "print(f\"ğŸ“ RTF: {round(rtf, 3)}\")\n",
        "print(f\"âœ… RTF Score (0â€“5): {rtf_score}\")\n",
        "\n",
        "# Playback audio\n",
        "display(Audio(\"output.wav\"))\n"
      ],
      "metadata": {
        "id": "X_HBQZvKPeyw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}